{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxk2gXK6vhNKxevpXx9bSv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarveshgadkari/ML/blob/main/ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear Regression\t**"
      ],
      "metadata": {
        "id": "oij1eu7UNtFq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h3qu0UshNcWW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"C:/Users/Lenovo/Desktop/ML/Untitled Folder/Housing.csv\")\n",
        "\n",
        "# Encode binary categorical columns\n",
        "binary_cols = ['mainroad', 'guestroom', 'basement', 'hotwaterheating', 'airconditioning', 'prefarea']\n",
        "for col in binary_cols:\n",
        "    df[col] = df[col].map({'yes': 1, 'no': 0})\n",
        "\n",
        "# One-hot encode 'furnishingstatus'\n",
        "df = pd.get_dummies(df, columns=['furnishingstatus'], drop_first=True)\n",
        "\n",
        "# Features and target\n",
        "X = df.drop(columns=['price'])\n",
        "y = df['price']\n",
        "\n",
        "# Split data\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = LinearRegression()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Evaluate\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"R-squared Score:\", r2)\n",
        "\n",
        "# Results DataFrame\n",
        "result = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
        "print(result)\n",
        "\n",
        "# Plot Actual vs Predicted\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred, color='blue', alpha=0.5)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], color='red', linewidth=2)\n",
        "plt.xlabel('Actual Price')\n",
        "plt.ylabel('Predicted Price')\n",
        "plt.title('Actual vs Predicted Prices (Test Data)')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " **DecisionTree**"
      ],
      "metadata": {
        "id": "XdGTzr_4f9Tw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load your CSV file\n",
        "df = pd.read_csv('titanic.csv')  # Make sure the path is correct\n",
        "\n",
        "# Drop columns you don't want\n",
        "df = df.drop(['age', 'embarked', 'class', 'who', 'deck', 'adult_male', 'embark_town', 'alive'], axis=1)\n",
        "\n",
        "# Drop missing values\n",
        "df = df.dropna()\n",
        "\n",
        "# Convert categorical variables to numeric\n",
        "df['sex'] = pd.get_dummies(df['sex'], drop_first=True)\n",
        "df['alone'] = pd.get_dummies(df['alone'], drop_first=True)\n",
        "\n",
        "# Features and target split\n",
        "X = df.drop('survived', axis=1)\n",
        "y = df['survived']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 1. No pruning\n",
        "m1 = DecisionTreeClassifier(random_state=42)\n",
        "m1.fit(X_train, y_train)\n",
        "y1_pred = m1.predict(X_test)\n",
        "print(\"Accuracy Score (No Pruning):\", accuracy_score(y_test, y1_pred))\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(m1, feature_names=X.columns, class_names=['Not Survived', 'Survived'], filled=True)\n",
        "plt.title(\"Decision Tree without Pruning\")\n",
        "plt.show()\n",
        "\n",
        "# 2. Pre-pruning\n",
        "m2 = DecisionTreeClassifier(max_depth=5, min_samples_split=10, random_state=42)\n",
        "m2.fit(X_train, y_train)\n",
        "y2_pred = m2.predict(X_test)\n",
        "print(\"Accuracy Score (Pre-Pruning):\", accuracy_score(y_test, y2_pred))\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(m2, feature_names=X.columns, class_names=['Not Survived', 'Survived'], filled=True)\n",
        "plt.title(\"Decision Tree with Pre-Pruning\")\n",
        "plt.show()\n",
        "\n",
        "# 3. Post-pruning\n",
        "m3 = DecisionTreeClassifier(random_state=42)\n",
        "m3.fit(X_train, y_train)\n",
        "path = m3.cost_complexity_pruning_path(X_train, y_train)\n",
        "ccp_alphas = path.ccp_alphas\n",
        "models = [DecisionTreeClassifier(random_state=42, ccp_alpha=alpha).fit(X_train, y_train) for alpha in ccp_alphas]\n",
        "accuracies = [accuracy_score(y_test, model.predict(X_test)) for model in models]\n",
        "best_alpha = ccp_alphas[np.argmax(accuracies)]\n",
        "best_model = DecisionTreeClassifier(random_state=42, ccp_alpha=best_alpha)\n",
        "best_model.fit(X_train, y_train)\n",
        "y3_pred = best_model.predict(X_test)\n",
        "print(\"Accuracy Score (Post-Pruning):\", accuracy_score(y_test, y3_pred))\n",
        "plt.figure(figsize=(20, 10))\n",
        "plot_tree(best_model, feature_names=X.columns, class_names=['Not Survived', 'Survived'], filled=True)\n",
        "plt.title(\"Decision Tree with Post-Pruning\")\n",
        "plt.show()\n",
        "\n",
        "# Classification reports\n",
        "print(\"\\nClassification Report (No Pruning):\\n\", classification_report(y_test, y1_pred))\n",
        "print(\"\\nClassification Report (Pre-Pruning):\\n\", classification_report(y_test, y2_pred))\n",
        "print(\"\\nClassification Report (Post-Pruning):\\n\", classification_report(y_test, y3_pred))\n",
        "\n",
        "# Confusion Matrices\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y1_pred, cmap='Blues')\n",
        "plt.title(\"Confusion Matrix (No Pruning)\")\n",
        "plt.show()\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y2_pred, cmap='Purples')\n",
        "plt.title(\"Confusion Matrix (Pre-Pruning)\")\n",
        "plt.show()\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y3_pred, cmap='Reds')\n",
        "plt.title(\"Confusion Matrix (Post-Pruning)\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "_9r-K8C1N4Rw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Naive Bayes **"
      ],
      "metadata": {
        "id": "WflAU-OYhRZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('C:/Users/ADMIN/Desktop/ML/adult.csv')\n",
        "\n",
        "# Clean data\n",
        "df.replace(' ?', np.nan, inplace=True)\n",
        "df.dropna(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Encode categorical features\n",
        "le = LabelEncoder()\n",
        "for column in df.columns:\n",
        "    if df[column].dtype == 'object':\n",
        "        df[column] = le.fit_transform(df[column])\n",
        "\n",
        "# Split features and target\n",
        "X = df.drop('income', axis=1)\n",
        "y = df['income']\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Naive Bayes model\n",
        "model = GaussianNB()\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_train = model.predict(X_train)\n",
        "\n",
        "# Evaluation\n",
        "print(\"Accuracy Score (Test):\", accuracy_score(y_test, y_pred))\n",
        "print(\"Accuracy Score (Train):\", accuracy_score(y_train, y_pred_train))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "labels = ['<=50K', '>50K']\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap='Reds')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "ImUBYoeJgFBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "K-**Means**"
      ],
      "metadata": {
        "id": "Aw8bSgEgh8MG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "\n",
        "# Set Seaborn style\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('C:/Users/ADMIN/Desktop/ML/Mall_Customers.csv')\n",
        "\n",
        "# Data overview\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "print(\"\\nDataset Info:\")\n",
        "print(df.info())\n",
        "\n",
        "print(\"\\nSummary Statistics:\")\n",
        "print(df.describe())\n",
        "\n",
        "print(\"\\nMissing Values in each column:\")\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Visualize feature distributions\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.histplot(data=df, kde=True)\n",
        "plt.title(\"Feature Distributions\")\n",
        "plt.show()\n",
        "\n",
        "# Encode 'Genre' column (Male/Female)\n",
        "label_encoder = LabelEncoder()\n",
        "df['Genre'] = label_encoder.fit_transform(df['Genre'])\n",
        "\n",
        "# Select features for clustering\n",
        "X = df[['Annual Income (k$)', 'Spending Score (1-100)']]\n",
        "\n",
        "# Scatter plot of raw data\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.scatter(X.iloc[:, 0], X.iloc[:, 1], s=50)\n",
        "plt.title(\"Raw Data Points (Unlabeled)\")\n",
        "plt.xlabel(\"Annual Income (k$)\")\n",
        "plt.ylabel(\"Spending Score (1-100)\")\n",
        "plt.show()\n",
        "\n",
        "# Feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Elbow method to find optimal K\n",
        "inertia = []\n",
        "K_range = range(1, 11)\n",
        "for k in K_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(X_scaled)\n",
        "    inertia.append(kmeans.inertia_)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(K_range, inertia, 'bo-')\n",
        "plt.title(\"Elbow Method For Optimal K\")\n",
        "plt.xlabel(\"Number of Clusters (K)\")\n",
        "plt.ylabel(\"Inertia (Within-Cluster Sum of Squares)\")\n",
        "plt.xticks(K_range)\n",
        "plt.show()\n",
        "\n",
        "# Optimal number of clusters selected based on elbow method\n",
        "optimal_k = 5  # because after k=5, there's no significant drop in inertia\n",
        "\n",
        "# Apply KMeans\n",
        "kmeans = KMeans(n_clusters=optimal_k, random_state=42)\n",
        "y_kmeans = kmeans.fit_predict(X_scaled)\n",
        "\n",
        "# Visualize Clusters\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.scatter(X_scaled[:, 0], X_scaled[:, 1], c=y_kmeans, cmap='viridis', s=50)\n",
        "centers = kmeans.cluster_centers_\n",
        "plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.75, marker='X', label='Centroids')\n",
        "plt.title(\"K-Means Clustering Result\")\n",
        "plt.xlabel(\"Annual Income (scaled)\")\n",
        "plt.ylabel(\"Spending Score (scaled)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Results\n",
        "print(\"Cluster Centers (in scaled space):\")\n",
        "print(centers)\n",
        "\n",
        "print(\"\\nFirst 10 Predicted Cluster Labels:\")\n",
        "print(y_kmeans[:10])\n"
      ],
      "metadata": {
        "id": "uGWhANY4haLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ANN**"
      ],
      "metadata": {
        "id": "KEPfw7fRiszQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Import Required Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "from google.colab import files\n",
        "\n",
        "# 2. Upload and Load Dataset\n",
        "uploaded = files.upload()\n",
        "data = pd.read_csv('Churn_Modelling.csv')\n",
        "\n",
        "# 3. Initial Data Exploration\n",
        "print(data.head())\n",
        "print(\"\\nData Info:\")\n",
        "print(data.info())\n",
        "print(\"\\nStatistical Summary:\")\n",
        "print(data.describe())\n",
        "print(\"\\nMissing Values Check:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# 4. Feature Selection\n",
        "X = data.iloc[:, 3:-1]  # Exclude RowNumber, CustomerId, Surname, and Exited (target)\n",
        "y = data.iloc[:, -1]    # Exited column is the target\n",
        "\n",
        "# 5. Encode Categorical Variables\n",
        "le = LabelEncoder()\n",
        "X['Gender'] = le.fit_transform(X['Gender'])  # Convert Male/Female to 1/0\n",
        "X = pd.get_dummies(X, columns=['Geography'], drop_first=True)  # One-hot encoding for Geography\n",
        "\n",
        "# 6. Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "# 7. Feature Scaling\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 8. Build the ANN\n",
        "ann = tf.keras.models.Sequential()\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu', input_shape=(X_train.shape[1],)))\n",
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))\n",
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))  # Output layer for binary classification\n",
        "\n",
        "# 9. Compile the ANN\n",
        "ann.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 10. Train the ANN\n",
        "history = ann.fit(X_train, y_train, batch_size=32, epochs=50, validation_data=(X_test, y_test))\n",
        "\n",
        "# 11. Make Predictions\n",
        "y_pred = ann.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)  # Convert probabilities to 0 or 1\n",
        "\n",
        "# 12. Evaluate the Model\n",
        "print(\"\\nAccuracy Score:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "id": "b2PU-_-yiDl1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " Bagging vs **Boosting**"
      ],
      "metadata": {
        "id": "Iu5Gwr9XjGzv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Import Required Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# 2. Load the Data\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.Series(iris.target, name='species')\n",
        "\n",
        "print(\"\\n🔍 Dataset Preview:\")\n",
        "print(X.head())\n",
        "\n",
        "print(\"\\n📊 Data Info:\")\n",
        "print(X.info())\n",
        "\n",
        "print(\"\\n📈 Class Distribution:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "# 3. Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 4. Bagging - Random Forest\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "\n",
        "# 5. Boosting - AdaBoost\n",
        "ada_model = AdaBoostClassifier(\n",
        "    estimator=DecisionTreeClassifier(max_depth=1),\n",
        "    n_estimators=50, random_state=42\n",
        ")\n",
        "ada_model.fit(X_train, y_train)\n",
        "y_pred_ada = ada_model.predict(X_test)\n",
        "\n",
        "# 6. Evaluation\n",
        "\n",
        "# 📊 Random Forest (Bagging)\n",
        "print(\"\\n🌲 Random Forest (Bagging) Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# Confusion Matrix for Random Forest\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap=\"Blues\",\n",
        "            xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
        "plt.title(\"Random Forest - Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# ⚡ AdaBoost (Boosting)\n",
        "print(\"\\n⚡ AdaBoost (Boosting) Results:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_ada))\n",
        "print(classification_report(y_test, y_pred_ada))\n",
        "\n",
        "# Confusion Matrix for AdaBoost\n",
        "cm_ada = confusion_matrix(y_test, y_pred_ada)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(cm_ada, annot=True, fmt='d', cmap=\"Greens\",\n",
        "            xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
        "plt.title(\"AdaBoost - Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n",
        "\n",
        "# 7. Conclusion\n",
        "print(\"\\n🔚 Conclusion:\")\n",
        "print(f\"✅ Random Forest Accuracy: {accuracy_score(y_test, y_pred_rf) * 100:.2f}%\")\n",
        "print(f\"✅ AdaBoost Accuracy     : {accuracy_score(y_test, y_pred_ada) * 100:.2f}%\")\n",
        "\n",
        "if accuracy_score(y_test, y_pred_rf) > accuracy_score(y_test, y_pred_ada):\n",
        "    print(\"🎯 Bagging (Random Forest) performed slightly better on the Iris dataset.\")\n",
        "else:\n",
        "    print(\"🎯 Boosting (AdaBoost) performed slightly better on the Iris dataset.\")\n"
      ],
      "metadata": {
        "id": "VX6EOzsMisXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "s5BHm68IjTNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "2Q82wXzbjVy1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# 2. Load Dataset\n",
        "# Replace 'your_file.csv' with your actual file\n",
        "data = pd.read_csv('your_file.csv')  # Example: 'Churn_Modelling.csv'\n",
        "print(\"\\n📋 Dataset Head:\")\n",
        "print(data.head())\n",
        "\n",
        "# 3. EDA - Check for missing values\n",
        "print(\"\\n🔍 Data Info:\")\n",
        "print(data.info())\n",
        "\n",
        "print(\"\\n🧼 Missing Values:\")\n",
        "print(data.isnull().sum())\n",
        "\n",
        "# 4. Define Features (X) and Target (y)\n",
        "# Update based on your dataset\n",
        "X = data.drop('target_column_name', axis=1)  # Replace with actual column name\n",
        "y = data['target_column_name']  # Replace with actual column name\n",
        "\n",
        "# 5. Handle Categorical Features\n",
        "# Convert object or category columns to numeric\n",
        "for col in X.select_dtypes(include=['object', 'category']).columns:\n",
        "    le = LabelEncoder()\n",
        "    X[col] = le.fit_transform(X[col])\n",
        "\n",
        "# 6. Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# 7. Feature Scaling (Optional for tree-based models, but useful if combining with other models)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# 8. Train Random Forest\n",
        "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# 9. Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# 10. Evaluate Model\n",
        "print(\"\\n✅ Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\n📉 Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
        "print(\"\\n📋 Classification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# 11. Feature Importance (Optional)\n",
        "importances = model.feature_importances_\n",
        "feature_names = X.columns\n",
        "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
        "importance_df = importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x='Importance', y='Feature', data=importance_df)\n",
        "plt.title('Feature Importances from Random Forest')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "UWVPXufWjIz9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}